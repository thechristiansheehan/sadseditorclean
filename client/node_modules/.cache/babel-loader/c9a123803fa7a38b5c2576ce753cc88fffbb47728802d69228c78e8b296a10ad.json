{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.PathError = exports.TokenData = void 0;\nexports.parse = parse;\nexports.compile = compile;\nexports.match = match;\nexports.pathToRegexp = pathToRegexp;\nexports.stringify = stringify;\nconst DEFAULT_DELIMITER = \"/\";\nconst NOOP_VALUE = value => value;\nconst ID_START = /^[$_\\p{ID_Start}]$/u;\nconst ID_CONTINUE = /^[$\\u200c\\u200d\\p{ID_Continue}]$/u;\nconst SIMPLE_TOKENS = {\n  // Groups.\n  \"{\": \"{\",\n  \"}\": \"}\",\n  // Reserved.\n  \"(\": \"(\",\n  \")\": \")\",\n  \"[\": \"[\",\n  \"]\": \"]\",\n  \"+\": \"+\",\n  \"?\": \"?\",\n  \"!\": \"!\"\n};\n/**\n * Escape text for stringify to path.\n */\nfunction escapeText(str) {\n  return str.replace(/[{}()\\[\\]+?!:*\\\\]/g, \"\\\\$&\");\n}\n/**\n * Escape a regular expression string.\n */\nfunction escape(str) {\n  return str.replace(/[.+*?^${}()[\\]|/\\\\]/g, \"\\\\$&\");\n}\n/**\n * Tokenized path instance.\n */\nclass TokenData {\n  constructor(tokens, originalPath) {\n    this.tokens = tokens;\n    this.originalPath = originalPath;\n  }\n}\nexports.TokenData = TokenData;\n/**\n * ParseError is thrown when there is an error processing the path.\n */\nclass PathError extends TypeError {\n  constructor(message, originalPath) {\n    let text = message;\n    if (originalPath) text += `: ${originalPath}`;\n    text += `; visit https://git.new/pathToRegexpError for info`;\n    super(text);\n    this.originalPath = originalPath;\n  }\n}\nexports.PathError = PathError;\n/**\n * Parse a string for the raw tokens.\n */\nfunction parse(str, options = {}) {\n  const {\n    encodePath = NOOP_VALUE\n  } = options;\n  const chars = [...str];\n  const tokens = [];\n  let index = 0;\n  let pos = 0;\n  function name() {\n    let value = \"\";\n    if (ID_START.test(chars[index])) {\n      do {\n        value += chars[index++];\n      } while (ID_CONTINUE.test(chars[index]));\n    } else if (chars[index] === '\"') {\n      let quoteStart = index;\n      while (index++ < chars.length) {\n        if (chars[index] === '\"') {\n          index++;\n          quoteStart = 0;\n          break;\n        }\n        // Increment over escape characters.\n        if (chars[index] === \"\\\\\") index++;\n        value += chars[index];\n      }\n      if (quoteStart) {\n        throw new PathError(`Unterminated quote at index ${quoteStart}`, str);\n      }\n    }\n    if (!value) {\n      throw new PathError(`Missing parameter name at index ${index}`, str);\n    }\n    return value;\n  }\n  while (index < chars.length) {\n    const value = chars[index];\n    const type = SIMPLE_TOKENS[value];\n    if (type) {\n      tokens.push({\n        type,\n        index: index++,\n        value\n      });\n    } else if (value === \"\\\\\") {\n      tokens.push({\n        type: \"escape\",\n        index: index++,\n        value: chars[index++]\n      });\n    } else if (value === \":\") {\n      tokens.push({\n        type: \"param\",\n        index: index++,\n        value: name()\n      });\n    } else if (value === \"*\") {\n      tokens.push({\n        type: \"wildcard\",\n        index: index++,\n        value: name()\n      });\n    } else {\n      tokens.push({\n        type: \"char\",\n        index: index++,\n        value\n      });\n    }\n  }\n  tokens.push({\n    type: \"end\",\n    index,\n    value: \"\"\n  });\n  function consumeUntil(endType) {\n    const output = [];\n    while (true) {\n      const token = tokens[pos++];\n      if (token.type === endType) break;\n      if (token.type === \"char\" || token.type === \"escape\") {\n        let path = token.value;\n        let cur = tokens[pos];\n        while (cur.type === \"char\" || cur.type === \"escape\") {\n          path += cur.value;\n          cur = tokens[++pos];\n        }\n        output.push({\n          type: \"text\",\n          value: encodePath(path)\n        });\n        continue;\n      }\n      if (token.type === \"param\" || token.type === \"wildcard\") {\n        output.push({\n          type: token.type,\n          name: token.value\n        });\n        continue;\n      }\n      if (token.type === \"{\") {\n        output.push({\n          type: \"group\",\n          tokens: consumeUntil(\"}\")\n        });\n        continue;\n      }\n      throw new PathError(`Unexpected ${token.type} at index ${token.index}, expected ${endType}`, str);\n    }\n    return output;\n  }\n  return new TokenData(consumeUntil(\"end\"), str);\n}\n/**\n * Compile a string to a template function for the path.\n */\nfunction compile(path, options = {}) {\n  const {\n    encode = encodeURIComponent,\n    delimiter = DEFAULT_DELIMITER\n  } = options;\n  const data = typeof path === \"object\" ? path : parse(path, options);\n  const fn = tokensToFunction(data.tokens, delimiter, encode);\n  return function path(params = {}) {\n    const [path, ...missing] = fn(params);\n    if (missing.length) {\n      throw new TypeError(`Missing parameters: ${missing.join(\", \")}`);\n    }\n    return path;\n  };\n}\nfunction tokensToFunction(tokens, delimiter, encode) {\n  const encoders = tokens.map(token => tokenToFunction(token, delimiter, encode));\n  return data => {\n    const result = [\"\"];\n    for (const encoder of encoders) {\n      const [value, ...extras] = encoder(data);\n      result[0] += value;\n      result.push(...extras);\n    }\n    return result;\n  };\n}\n/**\n * Convert a single token into a path building function.\n */\nfunction tokenToFunction(token, delimiter, encode) {\n  if (token.type === \"text\") return () => [token.value];\n  if (token.type === \"group\") {\n    const fn = tokensToFunction(token.tokens, delimiter, encode);\n    return data => {\n      const [value, ...missing] = fn(data);\n      if (!missing.length) return [value];\n      return [\"\"];\n    };\n  }\n  const encodeValue = encode || NOOP_VALUE;\n  if (token.type === \"wildcard\" && encode !== false) {\n    return data => {\n      const value = data[token.name];\n      if (value == null) return [\"\", token.name];\n      if (!Array.isArray(value) || value.length === 0) {\n        throw new TypeError(`Expected \"${token.name}\" to be a non-empty array`);\n      }\n      return [value.map((value, index) => {\n        if (typeof value !== \"string\") {\n          throw new TypeError(`Expected \"${token.name}/${index}\" to be a string`);\n        }\n        return encodeValue(value);\n      }).join(delimiter)];\n    };\n  }\n  return data => {\n    const value = data[token.name];\n    if (value == null) return [\"\", token.name];\n    if (typeof value !== \"string\") {\n      throw new TypeError(`Expected \"${token.name}\" to be a string`);\n    }\n    return [encodeValue(value)];\n  };\n}\n/**\n * Transform a path into a match function.\n */\nfunction match(path, options = {}) {\n  const {\n    decode = decodeURIComponent,\n    delimiter = DEFAULT_DELIMITER\n  } = options;\n  const {\n    regexp,\n    keys\n  } = pathToRegexp(path, options);\n  const decoders = keys.map(key => {\n    if (decode === false) return NOOP_VALUE;\n    if (key.type === \"param\") return decode;\n    return value => value.split(delimiter).map(decode);\n  });\n  return function match(input) {\n    const m = regexp.exec(input);\n    if (!m) return false;\n    const path = m[0];\n    const params = Object.create(null);\n    for (let i = 1; i < m.length; i++) {\n      if (m[i] === undefined) continue;\n      const key = keys[i - 1];\n      const decoder = decoders[i - 1];\n      params[key.name] = decoder(m[i]);\n    }\n    return {\n      path,\n      params\n    };\n  };\n}\nfunction pathToRegexp(path, options = {}) {\n  const {\n    delimiter = DEFAULT_DELIMITER,\n    end = true,\n    sensitive = false,\n    trailing = true\n  } = options;\n  const keys = [];\n  const flags = sensitive ? \"\" : \"i\";\n  const sources = [];\n  for (const input of pathsToArray(path, [])) {\n    const data = typeof input === \"object\" ? input : parse(input, options);\n    for (const tokens of flatten(data.tokens, 0, [])) {\n      sources.push(toRegExpSource(tokens, delimiter, keys, data.originalPath));\n    }\n  }\n  let pattern = `^(?:${sources.join(\"|\")})`;\n  if (trailing) pattern += `(?:${escape(delimiter)}$)?`;\n  pattern += end ? \"$\" : `(?=${escape(delimiter)}|$)`;\n  const regexp = new RegExp(pattern, flags);\n  return {\n    regexp,\n    keys\n  };\n}\n/**\n * Convert a path or array of paths into a flat array.\n */\nfunction pathsToArray(paths, init) {\n  if (Array.isArray(paths)) {\n    for (const p of paths) pathsToArray(p, init);\n  } else {\n    init.push(paths);\n  }\n  return init;\n}\n/**\n * Generate a flat list of sequence tokens from the given tokens.\n */\nfunction* flatten(tokens, index, init) {\n  if (index === tokens.length) {\n    return yield init;\n  }\n  const token = tokens[index];\n  if (token.type === \"group\") {\n    for (const seq of flatten(token.tokens, 0, init.slice())) {\n      yield* flatten(tokens, index + 1, seq);\n    }\n  } else {\n    init.push(token);\n  }\n  yield* flatten(tokens, index + 1, init);\n}\n/**\n * Transform a flat sequence of tokens into a regular expression.\n */\nfunction toRegExpSource(tokens, delimiter, keys, originalPath) {\n  let result = \"\";\n  let backtrack = \"\";\n  let isSafeSegmentParam = true;\n  for (const token of tokens) {\n    if (token.type === \"text\") {\n      result += escape(token.value);\n      backtrack += token.value;\n      isSafeSegmentParam || (isSafeSegmentParam = token.value.includes(delimiter));\n      continue;\n    }\n    if (token.type === \"param\" || token.type === \"wildcard\") {\n      if (!isSafeSegmentParam && !backtrack) {\n        throw new PathError(`Missing text before \"${token.name}\" ${token.type}`, originalPath);\n      }\n      if (token.type === \"param\") {\n        result += `(${negate(delimiter, isSafeSegmentParam ? \"\" : backtrack)}+)`;\n      } else {\n        result += `([\\\\s\\\\S]+)`;\n      }\n      keys.push(token);\n      backtrack = \"\";\n      isSafeSegmentParam = false;\n      continue;\n    }\n  }\n  return result;\n}\n/**\n * Block backtracking on previous text and ignore delimiter string.\n */\nfunction negate(delimiter, backtrack) {\n  if (backtrack.length < 2) {\n    if (delimiter.length < 2) return `[^${escape(delimiter + backtrack)}]`;\n    return `(?:(?!${escape(delimiter)})[^${escape(backtrack)}])`;\n  }\n  if (delimiter.length < 2) {\n    return `(?:(?!${escape(backtrack)})[^${escape(delimiter)}])`;\n  }\n  return `(?:(?!${escape(backtrack)}|${escape(delimiter)})[\\\\s\\\\S])`;\n}\n/**\n * Stringify an array of tokens into a path string.\n */\nfunction stringifyTokens(tokens) {\n  let value = \"\";\n  let i = 0;\n  function name(value) {\n    const isSafe = isNameSafe(value) && isNextNameSafe(tokens[i]);\n    return isSafe ? value : JSON.stringify(value);\n  }\n  while (i < tokens.length) {\n    const token = tokens[i++];\n    if (token.type === \"text\") {\n      value += escapeText(token.value);\n      continue;\n    }\n    if (token.type === \"group\") {\n      value += `{${stringifyTokens(token.tokens)}}`;\n      continue;\n    }\n    if (token.type === \"param\") {\n      value += `:${name(token.name)}`;\n      continue;\n    }\n    if (token.type === \"wildcard\") {\n      value += `*${name(token.name)}`;\n      continue;\n    }\n    throw new TypeError(`Unknown token type: ${token.type}`);\n  }\n  return value;\n}\n/**\n * Stringify token data into a path string.\n */\nfunction stringify(data) {\n  return stringifyTokens(data.tokens);\n}\n/**\n * Validate the parameter name contains valid ID characters.\n */\nfunction isNameSafe(name) {\n  const [first, ...rest] = name;\n  return ID_START.test(first) && rest.every(char => ID_CONTINUE.test(char));\n}\n/**\n * Validate the next token does not interfere with the current param name.\n */\nfunction isNextNameSafe(token) {\n  if (token && token.type === \"text\") return !ID_CONTINUE.test(token.value[0]);\n  return true;\n}","map":{"version":3,"names":["exports","parse","compile","match","pathToRegexp","stringify","DEFAULT_DELIMITER","NOOP_VALUE","value","ID_START","ID_CONTINUE","SIMPLE_TOKENS","escapeText","str","replace","escape","TokenData","constructor","tokens","originalPath","PathError","TypeError","message","text","options","encodePath","chars","index","pos","name","test","quoteStart","length","type","push","consumeUntil","endType","output","token","path","cur","encode","encodeURIComponent","delimiter","data","fn","tokensToFunction","params","missing","join","encoders","map","tokenToFunction","result","encoder","extras","encodeValue","Array","isArray","decode","decodeURIComponent","regexp","keys","decoders","key","split","input","m","exec","Object","create","i","undefined","decoder","end","sensitive","trailing","flags","sources","pathsToArray","flatten","toRegExpSource","pattern","RegExp","paths","init","p","seq","slice","backtrack","isSafeSegmentParam","includes","negate","stringifyTokens","isSafe","isNameSafe","isNextNameSafe","JSON","first","rest","every","char"],"sources":["C:\\Users\\Flame\\sadseditor\\sadseditor\\client\\node_modules\\path-to-regexp\\src\\index.ts"],"sourcesContent":["const DEFAULT_DELIMITER = \"/\";\nconst NOOP_VALUE = (value: string) => value;\nconst ID_START = /^[$_\\p{ID_Start}]$/u;\nconst ID_CONTINUE = /^[$\\u200c\\u200d\\p{ID_Continue}]$/u;\n\n/**\n * Encode a string into another string.\n */\nexport type Encode = (value: string) => string;\n\n/**\n * Decode a string into another string.\n */\nexport type Decode = (value: string) => string;\n\nexport interface ParseOptions {\n  /**\n   * A function for encoding input strings.\n   */\n  encodePath?: Encode;\n}\n\nexport interface PathToRegexpOptions {\n  /**\n   * Matches the path completely without trailing characters. (default: `true`)\n   */\n  end?: boolean;\n  /**\n   * Allows optional trailing delimiter to match. (default: `true`)\n   */\n  trailing?: boolean;\n  /**\n   * Match will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * The default delimiter for segments. (default: `'/'`)\n   */\n  delimiter?: string;\n}\n\nexport interface MatchOptions extends PathToRegexpOptions {\n  /**\n   * Function for decoding strings for params, or `false` to disable entirely. (default: `decodeURIComponent`)\n   */\n  decode?: Decode | false;\n}\n\nexport interface CompileOptions {\n  /**\n   * Function for encoding input strings for output into the path, or `false` to disable entirely. (default: `encodeURIComponent`)\n   */\n  encode?: Encode | false;\n  /**\n   * The default delimiter for segments. (default: `'/'`)\n   */\n  delimiter?: string;\n}\n\ntype TokenType =\n  | \"{\"\n  | \"}\"\n  | \"wildcard\"\n  | \"param\"\n  | \"char\"\n  | \"escape\"\n  | \"end\"\n  // Reserved for use or ambiguous due to past use.\n  | \"(\"\n  | \")\"\n  | \"[\"\n  | \"]\"\n  | \"+\"\n  | \"?\"\n  | \"!\";\n\n/**\n * Tokenizer results.\n */\ninterface LexToken {\n  type: TokenType;\n  index: number;\n  value: string;\n}\n\nconst SIMPLE_TOKENS: Record<string, TokenType> = {\n  // Groups.\n  \"{\": \"{\",\n  \"}\": \"}\",\n  // Reserved.\n  \"(\": \"(\",\n  \")\": \")\",\n  \"[\": \"[\",\n  \"]\": \"]\",\n  \"+\": \"+\",\n  \"?\": \"?\",\n  \"!\": \"!\",\n};\n\n/**\n * Escape text for stringify to path.\n */\nfunction escapeText(str: string) {\n  return str.replace(/[{}()\\[\\]+?!:*\\\\]/g, \"\\\\$&\");\n}\n\n/**\n * Escape a regular expression string.\n */\nfunction escape(str: string) {\n  return str.replace(/[.+*?^${}()[\\]|/\\\\]/g, \"\\\\$&\");\n}\n\n/**\n * Plain text.\n */\nexport interface Text {\n  type: \"text\";\n  value: string;\n}\n\n/**\n * A parameter designed to match arbitrary text within a segment.\n */\nexport interface Parameter {\n  type: \"param\";\n  name: string;\n}\n\n/**\n * A wildcard parameter designed to match multiple segments.\n */\nexport interface Wildcard {\n  type: \"wildcard\";\n  name: string;\n}\n\n/**\n * A set of possible tokens to expand when matching.\n */\nexport interface Group {\n  type: \"group\";\n  tokens: Token[];\n}\n\n/**\n * A token that corresponds with a regexp capture.\n */\nexport type Key = Parameter | Wildcard;\n\n/**\n * A sequence of `path-to-regexp` keys that match capturing groups.\n */\nexport type Keys = Array<Key>;\n\n/**\n * A sequence of path match characters.\n */\nexport type Token = Text | Parameter | Wildcard | Group;\n\n/**\n * Tokenized path instance.\n */\nexport class TokenData {\n  constructor(\n    public readonly tokens: Token[],\n    public readonly originalPath?: string,\n  ) {}\n}\n\n/**\n * ParseError is thrown when there is an error processing the path.\n */\nexport class PathError extends TypeError {\n  constructor(\n    message: string,\n    public readonly originalPath: string | undefined,\n  ) {\n    let text = message;\n    if (originalPath) text += `: ${originalPath}`;\n    text += `; visit https://git.new/pathToRegexpError for info`;\n    super(text);\n  }\n}\n\n/**\n * Parse a string for the raw tokens.\n */\nexport function parse(str: string, options: ParseOptions = {}): TokenData {\n  const { encodePath = NOOP_VALUE } = options;\n  const chars = [...str];\n  const tokens: Array<LexToken> = [];\n  let index = 0;\n  let pos = 0;\n\n  function name() {\n    let value = \"\";\n\n    if (ID_START.test(chars[index])) {\n      do {\n        value += chars[index++];\n      } while (ID_CONTINUE.test(chars[index]));\n    } else if (chars[index] === '\"') {\n      let quoteStart = index;\n\n      while (index++ < chars.length) {\n        if (chars[index] === '\"') {\n          index++;\n          quoteStart = 0;\n          break;\n        }\n\n        // Increment over escape characters.\n        if (chars[index] === \"\\\\\") index++;\n\n        value += chars[index];\n      }\n\n      if (quoteStart) {\n        throw new PathError(`Unterminated quote at index ${quoteStart}`, str);\n      }\n    }\n\n    if (!value) {\n      throw new PathError(`Missing parameter name at index ${index}`, str);\n    }\n\n    return value;\n  }\n\n  while (index < chars.length) {\n    const value = chars[index];\n    const type = SIMPLE_TOKENS[value];\n\n    if (type) {\n      tokens.push({ type, index: index++, value });\n    } else if (value === \"\\\\\") {\n      tokens.push({ type: \"escape\", index: index++, value: chars[index++] });\n    } else if (value === \":\") {\n      tokens.push({ type: \"param\", index: index++, value: name() });\n    } else if (value === \"*\") {\n      tokens.push({ type: \"wildcard\", index: index++, value: name() });\n    } else {\n      tokens.push({ type: \"char\", index: index++, value });\n    }\n  }\n\n  tokens.push({ type: \"end\", index, value: \"\" });\n\n  function consumeUntil(endType: TokenType): Token[] {\n    const output: Token[] = [];\n\n    while (true) {\n      const token = tokens[pos++];\n      if (token.type === endType) break;\n\n      if (token.type === \"char\" || token.type === \"escape\") {\n        let path = token.value;\n        let cur = tokens[pos];\n\n        while (cur.type === \"char\" || cur.type === \"escape\") {\n          path += cur.value;\n          cur = tokens[++pos];\n        }\n\n        output.push({\n          type: \"text\",\n          value: encodePath(path),\n        });\n        continue;\n      }\n\n      if (token.type === \"param\" || token.type === \"wildcard\") {\n        output.push({\n          type: token.type,\n          name: token.value,\n        });\n        continue;\n      }\n\n      if (token.type === \"{\") {\n        output.push({\n          type: \"group\",\n          tokens: consumeUntil(\"}\"),\n        });\n        continue;\n      }\n\n      throw new PathError(\n        `Unexpected ${token.type} at index ${token.index}, expected ${endType}`,\n        str,\n      );\n    }\n\n    return output;\n  }\n\n  return new TokenData(consumeUntil(\"end\"), str);\n}\n\n/**\n * Compile a string to a template function for the path.\n */\nexport function compile<P extends ParamData = ParamData>(\n  path: Path,\n  options: CompileOptions & ParseOptions = {},\n) {\n  const { encode = encodeURIComponent, delimiter = DEFAULT_DELIMITER } =\n    options;\n  const data = typeof path === \"object\" ? path : parse(path, options);\n  const fn = tokensToFunction(data.tokens, delimiter, encode);\n\n  return function path(params: P = {} as P) {\n    const [path, ...missing] = fn(params);\n    if (missing.length) {\n      throw new TypeError(`Missing parameters: ${missing.join(\", \")}`);\n    }\n    return path;\n  };\n}\n\nexport type ParamData = Partial<Record<string, string | string[]>>;\nexport type PathFunction<P extends ParamData> = (data?: P) => string;\n\nfunction tokensToFunction(\n  tokens: Token[],\n  delimiter: string,\n  encode: Encode | false,\n) {\n  const encoders = tokens.map((token) =>\n    tokenToFunction(token, delimiter, encode),\n  );\n\n  return (data: ParamData) => {\n    const result: string[] = [\"\"];\n\n    for (const encoder of encoders) {\n      const [value, ...extras] = encoder(data);\n      result[0] += value;\n      result.push(...extras);\n    }\n\n    return result;\n  };\n}\n\n/**\n * Convert a single token into a path building function.\n */\nfunction tokenToFunction(\n  token: Token,\n  delimiter: string,\n  encode: Encode | false,\n): (data: ParamData) => string[] {\n  if (token.type === \"text\") return () => [token.value];\n\n  if (token.type === \"group\") {\n    const fn = tokensToFunction(token.tokens, delimiter, encode);\n\n    return (data) => {\n      const [value, ...missing] = fn(data);\n      if (!missing.length) return [value];\n      return [\"\"];\n    };\n  }\n\n  const encodeValue = encode || NOOP_VALUE;\n\n  if (token.type === \"wildcard\" && encode !== false) {\n    return (data) => {\n      const value = data[token.name];\n      if (value == null) return [\"\", token.name];\n\n      if (!Array.isArray(value) || value.length === 0) {\n        throw new TypeError(`Expected \"${token.name}\" to be a non-empty array`);\n      }\n\n      return [\n        value\n          .map((value, index) => {\n            if (typeof value !== \"string\") {\n              throw new TypeError(\n                `Expected \"${token.name}/${index}\" to be a string`,\n              );\n            }\n\n            return encodeValue(value);\n          })\n          .join(delimiter),\n      ];\n    };\n  }\n\n  return (data) => {\n    const value = data[token.name];\n    if (value == null) return [\"\", token.name];\n\n    if (typeof value !== \"string\") {\n      throw new TypeError(`Expected \"${token.name}\" to be a string`);\n    }\n\n    return [encodeValue(value)];\n  };\n}\n\n/**\n * A match result contains data about the path match.\n */\nexport interface MatchResult<P extends ParamData> {\n  path: string;\n  params: P;\n}\n\n/**\n * A match is either `false` (no match) or a match result.\n */\nexport type Match<P extends ParamData> = false | MatchResult<P>;\n\n/**\n * The match function takes a string and returns whether it matched the path.\n */\nexport type MatchFunction<P extends ParamData> = (path: string) => Match<P>;\n\n/**\n * Supported path types.\n */\nexport type Path = string | TokenData;\n\n/**\n * Transform a path into a match function.\n */\nexport function match<P extends ParamData>(\n  path: Path | Path[],\n  options: MatchOptions & ParseOptions = {},\n): MatchFunction<P> {\n  const { decode = decodeURIComponent, delimiter = DEFAULT_DELIMITER } =\n    options;\n  const { regexp, keys } = pathToRegexp(path, options);\n\n  const decoders = keys.map((key) => {\n    if (decode === false) return NOOP_VALUE;\n    if (key.type === \"param\") return decode;\n    return (value: string) => value.split(delimiter).map(decode);\n  });\n\n  return function match(input: string) {\n    const m = regexp.exec(input);\n    if (!m) return false;\n\n    const path = m[0];\n    const params = Object.create(null);\n\n    for (let i = 1; i < m.length; i++) {\n      if (m[i] === undefined) continue;\n\n      const key = keys[i - 1];\n      const decoder = decoders[i - 1];\n      params[key.name] = decoder(m[i]);\n    }\n\n    return { path, params };\n  };\n}\n\nexport function pathToRegexp(\n  path: Path | Path[],\n  options: PathToRegexpOptions & ParseOptions = {},\n) {\n  const {\n    delimiter = DEFAULT_DELIMITER,\n    end = true,\n    sensitive = false,\n    trailing = true,\n  } = options;\n  const keys: Keys = [];\n  const flags = sensitive ? \"\" : \"i\";\n  const sources: string[] = [];\n\n  for (const input of pathsToArray(path, [])) {\n    const data = typeof input === \"object\" ? input : parse(input, options);\n    for (const tokens of flatten(data.tokens, 0, [])) {\n      sources.push(toRegExpSource(tokens, delimiter, keys, data.originalPath));\n    }\n  }\n\n  let pattern = `^(?:${sources.join(\"|\")})`;\n  if (trailing) pattern += `(?:${escape(delimiter)}$)?`;\n  pattern += end ? \"$\" : `(?=${escape(delimiter)}|$)`;\n\n  const regexp = new RegExp(pattern, flags);\n  return { regexp, keys };\n}\n\n/**\n * Convert a path or array of paths into a flat array.\n */\nfunction pathsToArray(paths: Path | Path[], init: Path[]): Path[] {\n  if (Array.isArray(paths)) {\n    for (const p of paths) pathsToArray(p, init);\n  } else {\n    init.push(paths);\n  }\n  return init;\n}\n\n/**\n * Flattened token set.\n */\ntype FlatToken = Text | Parameter | Wildcard;\n\n/**\n * Generate a flat list of sequence tokens from the given tokens.\n */\nfunction* flatten(\n  tokens: Token[],\n  index: number,\n  init: FlatToken[],\n): Generator<FlatToken[]> {\n  if (index === tokens.length) {\n    return yield init;\n  }\n\n  const token = tokens[index];\n\n  if (token.type === \"group\") {\n    for (const seq of flatten(token.tokens, 0, init.slice())) {\n      yield* flatten(tokens, index + 1, seq);\n    }\n  } else {\n    init.push(token);\n  }\n\n  yield* flatten(tokens, index + 1, init);\n}\n\n/**\n * Transform a flat sequence of tokens into a regular expression.\n */\nfunction toRegExpSource(\n  tokens: FlatToken[],\n  delimiter: string,\n  keys: Keys,\n  originalPath: string | undefined,\n): string {\n  let result = \"\";\n  let backtrack = \"\";\n  let isSafeSegmentParam = true;\n\n  for (const token of tokens) {\n    if (token.type === \"text\") {\n      result += escape(token.value);\n      backtrack += token.value;\n      isSafeSegmentParam ||= token.value.includes(delimiter);\n      continue;\n    }\n\n    if (token.type === \"param\" || token.type === \"wildcard\") {\n      if (!isSafeSegmentParam && !backtrack) {\n        throw new PathError(\n          `Missing text before \"${token.name}\" ${token.type}`,\n          originalPath,\n        );\n      }\n\n      if (token.type === \"param\") {\n        result += `(${negate(delimiter, isSafeSegmentParam ? \"\" : backtrack)}+)`;\n      } else {\n        result += `([\\\\s\\\\S]+)`;\n      }\n\n      keys.push(token);\n      backtrack = \"\";\n      isSafeSegmentParam = false;\n      continue;\n    }\n  }\n\n  return result;\n}\n\n/**\n * Block backtracking on previous text and ignore delimiter string.\n */\nfunction negate(delimiter: string, backtrack: string): string {\n  if (backtrack.length < 2) {\n    if (delimiter.length < 2) return `[^${escape(delimiter + backtrack)}]`;\n    return `(?:(?!${escape(delimiter)})[^${escape(backtrack)}])`;\n  }\n  if (delimiter.length < 2) {\n    return `(?:(?!${escape(backtrack)})[^${escape(delimiter)}])`;\n  }\n  return `(?:(?!${escape(backtrack)}|${escape(delimiter)})[\\\\s\\\\S])`;\n}\n\n/**\n * Stringify an array of tokens into a path string.\n */\nfunction stringifyTokens(tokens: Token[]): string {\n  let value = \"\";\n  let i = 0;\n\n  function name(value: string) {\n    const isSafe = isNameSafe(value) && isNextNameSafe(tokens[i]);\n    return isSafe ? value : JSON.stringify(value);\n  }\n\n  while (i < tokens.length) {\n    const token = tokens[i++];\n\n    if (token.type === \"text\") {\n      value += escapeText(token.value);\n      continue;\n    }\n\n    if (token.type === \"group\") {\n      value += `{${stringifyTokens(token.tokens)}}`;\n      continue;\n    }\n\n    if (token.type === \"param\") {\n      value += `:${name(token.name)}`;\n      continue;\n    }\n\n    if (token.type === \"wildcard\") {\n      value += `*${name(token.name)}`;\n      continue;\n    }\n\n    throw new TypeError(`Unknown token type: ${(token as any).type}`);\n  }\n\n  return value;\n}\n\n/**\n * Stringify token data into a path string.\n */\nexport function stringify(data: TokenData): string {\n  return stringifyTokens(data.tokens);\n}\n\n/**\n * Validate the parameter name contains valid ID characters.\n */\nfunction isNameSafe(name: string): boolean {\n  const [first, ...rest] = name;\n  return ID_START.test(first) && rest.every((char) => ID_CONTINUE.test(char));\n}\n\n/**\n * Validate the next token does not interfere with the current param name.\n */\nfunction isNextNameSafe(token: Token | undefined): boolean {\n  if (token && token.type === \"text\") return !ID_CONTINUE.test(token.value[0]);\n  return true;\n}\n"],"mappings":";;;;;;AA4LAA,OAAA,CAAAC,KAAA,GAAAA,KAAA;AAmHAD,OAAA,CAAAE,OAAA,GAAAA,OAAA;AAgIAF,OAAA,CAAAG,KAAA,GAAAA,KAAA;AAiCAH,OAAA,CAAAI,YAAA,GAAAA,YAAA;AA8KAJ,OAAA,CAAAK,SAAA,GAAAA,SAAA;AA9nBA,MAAMC,iBAAiB,GAAG,GAAG;AAC7B,MAAMC,UAAU,GAAIC,KAAa,IAAKA,KAAK;AAC3C,MAAMC,QAAQ,GAAG,qBAAqB;AACtC,MAAMC,WAAW,GAAG,mCAAmC;AAkFvD,MAAMC,aAAa,GAA8B;EAC/C;EACA,GAAG,EAAE,GAAG;EACR,GAAG,EAAE,GAAG;EACR;EACA,GAAG,EAAE,GAAG;EACR,GAAG,EAAE,GAAG;EACR,GAAG,EAAE,GAAG;EACR,GAAG,EAAE,GAAG;EACR,GAAG,EAAE,GAAG;EACR,GAAG,EAAE,GAAG;EACR,GAAG,EAAE;CACN;AAED;;;AAGA,SAASC,UAAUA,CAACC,GAAW;EAC7B,OAAOA,GAAG,CAACC,OAAO,CAAC,oBAAoB,EAAE,MAAM,CAAC;AAClD;AAEA;;;AAGA,SAASC,MAAMA,CAACF,GAAW;EACzB,OAAOA,GAAG,CAACC,OAAO,CAAC,sBAAsB,EAAE,MAAM,CAAC;AACpD;AAiDA;;;AAGA,MAAaE,SAAS;EACpBC,YACkBC,MAAe,EACfC,YAAqB;IADrB,KAAAD,MAAM,GAANA,MAAM;IACN,KAAAC,YAAY,GAAZA,YAAY;EAC3B;;AAJLnB,OAAA,CAAAgB,SAAA,GAAAA,SAAA;AAOA;;;AAGA,MAAaI,SAAU,SAAQC,SAAS;EACtCJ,YACEK,OAAe,EACCH,YAAgC;IAEhD,IAAII,IAAI,GAAGD,OAAO;IAClB,IAAIH,YAAY,EAAEI,IAAI,IAAI,KAAKJ,YAAY,EAAE;IAC7CI,IAAI,IAAI,oDAAoD;IAC5D,KAAK,CAACA,IAAI,CAAC;IALK,KAAAJ,YAAY,GAAZA,YAAY;EAM9B;;AATFnB,OAAA,CAAAoB,SAAA,GAAAA,SAAA;AAYA;;;AAGA,SAAgBnB,KAAKA,CAACY,GAAW,EAAEW,OAAA,GAAwB,EAAE;EAC3D,MAAM;IAAEC,UAAU,GAAGlB;EAAU,CAAE,GAAGiB,OAAO;EAC3C,MAAME,KAAK,GAAG,CAAC,GAAGb,GAAG,CAAC;EACtB,MAAMK,MAAM,GAAoB,EAAE;EAClC,IAAIS,KAAK,GAAG,CAAC;EACb,IAAIC,GAAG,GAAG,CAAC;EAEX,SAASC,IAAIA,CAAA;IACX,IAAIrB,KAAK,GAAG,EAAE;IAEd,IAAIC,QAAQ,CAACqB,IAAI,CAACJ,KAAK,CAACC,KAAK,CAAC,CAAC,EAAE;MAC/B,GAAG;QACDnB,KAAK,IAAIkB,KAAK,CAACC,KAAK,EAAE,CAAC;MACzB,CAAC,QAAQjB,WAAW,CAACoB,IAAI,CAACJ,KAAK,CAACC,KAAK,CAAC,CAAC;IACzC,CAAC,MAAM,IAAID,KAAK,CAACC,KAAK,CAAC,KAAK,GAAG,EAAE;MAC/B,IAAII,UAAU,GAAGJ,KAAK;MAEtB,OAAOA,KAAK,EAAE,GAAGD,KAAK,CAACM,MAAM,EAAE;QAC7B,IAAIN,KAAK,CAACC,KAAK,CAAC,KAAK,GAAG,EAAE;UACxBA,KAAK,EAAE;UACPI,UAAU,GAAG,CAAC;UACd;QACF;QAEA;QACA,IAAIL,KAAK,CAACC,KAAK,CAAC,KAAK,IAAI,EAAEA,KAAK,EAAE;QAElCnB,KAAK,IAAIkB,KAAK,CAACC,KAAK,CAAC;MACvB;MAEA,IAAII,UAAU,EAAE;QACd,MAAM,IAAIX,SAAS,CAAC,+BAA+BW,UAAU,EAAE,EAAElB,GAAG,CAAC;MACvE;IACF;IAEA,IAAI,CAACL,KAAK,EAAE;MACV,MAAM,IAAIY,SAAS,CAAC,mCAAmCO,KAAK,EAAE,EAAEd,GAAG,CAAC;IACtE;IAEA,OAAOL,KAAK;EACd;EAEA,OAAOmB,KAAK,GAAGD,KAAK,CAACM,MAAM,EAAE;IAC3B,MAAMxB,KAAK,GAAGkB,KAAK,CAACC,KAAK,CAAC;IAC1B,MAAMM,IAAI,GAAGtB,aAAa,CAACH,KAAK,CAAC;IAEjC,IAAIyB,IAAI,EAAE;MACRf,MAAM,CAACgB,IAAI,CAAC;QAAED,IAAI;QAAEN,KAAK,EAAEA,KAAK,EAAE;QAAEnB;MAAK,CAAE,CAAC;IAC9C,CAAC,MAAM,IAAIA,KAAK,KAAK,IAAI,EAAE;MACzBU,MAAM,CAACgB,IAAI,CAAC;QAAED,IAAI,EAAE,QAAQ;QAAEN,KAAK,EAAEA,KAAK,EAAE;QAAEnB,KAAK,EAAEkB,KAAK,CAACC,KAAK,EAAE;MAAC,CAAE,CAAC;IACxE,CAAC,MAAM,IAAInB,KAAK,KAAK,GAAG,EAAE;MACxBU,MAAM,CAACgB,IAAI,CAAC;QAAED,IAAI,EAAE,OAAO;QAAEN,KAAK,EAAEA,KAAK,EAAE;QAAEnB,KAAK,EAAEqB,IAAI;MAAE,CAAE,CAAC;IAC/D,CAAC,MAAM,IAAIrB,KAAK,KAAK,GAAG,EAAE;MACxBU,MAAM,CAACgB,IAAI,CAAC;QAAED,IAAI,EAAE,UAAU;QAAEN,KAAK,EAAEA,KAAK,EAAE;QAAEnB,KAAK,EAAEqB,IAAI;MAAE,CAAE,CAAC;IAClE,CAAC,MAAM;MACLX,MAAM,CAACgB,IAAI,CAAC;QAAED,IAAI,EAAE,MAAM;QAAEN,KAAK,EAAEA,KAAK,EAAE;QAAEnB;MAAK,CAAE,CAAC;IACtD;EACF;EAEAU,MAAM,CAACgB,IAAI,CAAC;IAAED,IAAI,EAAE,KAAK;IAAEN,KAAK;IAAEnB,KAAK,EAAE;EAAE,CAAE,CAAC;EAE9C,SAAS2B,YAAYA,CAACC,OAAkB;IACtC,MAAMC,MAAM,GAAY,EAAE;IAE1B,OAAO,IAAI,EAAE;MACX,MAAMC,KAAK,GAAGpB,MAAM,CAACU,GAAG,EAAE,CAAC;MAC3B,IAAIU,KAAK,CAACL,IAAI,KAAKG,OAAO,EAAE;MAE5B,IAAIE,KAAK,CAACL,IAAI,KAAK,MAAM,IAAIK,KAAK,CAACL,IAAI,KAAK,QAAQ,EAAE;QACpD,IAAIM,IAAI,GAAGD,KAAK,CAAC9B,KAAK;QACtB,IAAIgC,GAAG,GAAGtB,MAAM,CAACU,GAAG,CAAC;QAErB,OAAOY,GAAG,CAACP,IAAI,KAAK,MAAM,IAAIO,GAAG,CAACP,IAAI,KAAK,QAAQ,EAAE;UACnDM,IAAI,IAAIC,GAAG,CAAChC,KAAK;UACjBgC,GAAG,GAAGtB,MAAM,CAAC,EAAEU,GAAG,CAAC;QACrB;QAEAS,MAAM,CAACH,IAAI,CAAC;UACVD,IAAI,EAAE,MAAM;UACZzB,KAAK,EAAEiB,UAAU,CAACc,IAAI;SACvB,CAAC;QACF;MACF;MAEA,IAAID,KAAK,CAACL,IAAI,KAAK,OAAO,IAAIK,KAAK,CAACL,IAAI,KAAK,UAAU,EAAE;QACvDI,MAAM,CAACH,IAAI,CAAC;UACVD,IAAI,EAAEK,KAAK,CAACL,IAAI;UAChBJ,IAAI,EAAES,KAAK,CAAC9B;SACb,CAAC;QACF;MACF;MAEA,IAAI8B,KAAK,CAACL,IAAI,KAAK,GAAG,EAAE;QACtBI,MAAM,CAACH,IAAI,CAAC;UACVD,IAAI,EAAE,OAAO;UACbf,MAAM,EAAEiB,YAAY,CAAC,GAAG;SACzB,CAAC;QACF;MACF;MAEA,MAAM,IAAIf,SAAS,CACjB,cAAckB,KAAK,CAACL,IAAI,aAAaK,KAAK,CAACX,KAAK,cAAcS,OAAO,EAAE,EACvEvB,GAAG,CACJ;IACH;IAEA,OAAOwB,MAAM;EACf;EAEA,OAAO,IAAIrB,SAAS,CAACmB,YAAY,CAAC,KAAK,CAAC,EAAEtB,GAAG,CAAC;AAChD;AAEA;;;AAGA,SAAgBX,OAAOA,CACrBqC,IAAU,EACVf,OAAA,GAAyC,EAAE;EAE3C,MAAM;IAAEiB,MAAM,GAAGC,kBAAkB;IAAEC,SAAS,GAAGrC;EAAiB,CAAE,GAClEkB,OAAO;EACT,MAAMoB,IAAI,GAAG,OAAOL,IAAI,KAAK,QAAQ,GAAGA,IAAI,GAAGtC,KAAK,CAACsC,IAAI,EAAEf,OAAO,CAAC;EACnE,MAAMqB,EAAE,GAAGC,gBAAgB,CAACF,IAAI,CAAC1B,MAAM,EAAEyB,SAAS,EAAEF,MAAM,CAAC;EAE3D,OAAO,SAASF,IAAIA,CAACQ,MAAA,GAAY,EAAO;IACtC,MAAM,CAACR,IAAI,EAAE,GAAGS,OAAO,CAAC,GAAGH,EAAE,CAACE,MAAM,CAAC;IACrC,IAAIC,OAAO,CAAChB,MAAM,EAAE;MAClB,MAAM,IAAIX,SAAS,CAAC,uBAAuB2B,OAAO,CAACC,IAAI,CAAC,IAAI,CAAC,EAAE,CAAC;IAClE;IACA,OAAOV,IAAI;EACb,CAAC;AACH;AAKA,SAASO,gBAAgBA,CACvB5B,MAAe,EACfyB,SAAiB,EACjBF,MAAsB;EAEtB,MAAMS,QAAQ,GAAGhC,MAAM,CAACiC,GAAG,CAAEb,KAAK,IAChCc,eAAe,CAACd,KAAK,EAAEK,SAAS,EAAEF,MAAM,CAAC,CAC1C;EAED,OAAQG,IAAe,IAAI;IACzB,MAAMS,MAAM,GAAa,CAAC,EAAE,CAAC;IAE7B,KAAK,MAAMC,OAAO,IAAIJ,QAAQ,EAAE;MAC9B,MAAM,CAAC1C,KAAK,EAAE,GAAG+C,MAAM,CAAC,GAAGD,OAAO,CAACV,IAAI,CAAC;MACxCS,MAAM,CAAC,CAAC,CAAC,IAAI7C,KAAK;MAClB6C,MAAM,CAACnB,IAAI,CAAC,GAAGqB,MAAM,CAAC;IACxB;IAEA,OAAOF,MAAM;EACf,CAAC;AACH;AAEA;;;AAGA,SAASD,eAAeA,CACtBd,KAAY,EACZK,SAAiB,EACjBF,MAAsB;EAEtB,IAAIH,KAAK,CAACL,IAAI,KAAK,MAAM,EAAE,OAAO,MAAM,CAACK,KAAK,CAAC9B,KAAK,CAAC;EAErD,IAAI8B,KAAK,CAACL,IAAI,KAAK,OAAO,EAAE;IAC1B,MAAMY,EAAE,GAAGC,gBAAgB,CAACR,KAAK,CAACpB,MAAM,EAAEyB,SAAS,EAAEF,MAAM,CAAC;IAE5D,OAAQG,IAAI,IAAI;MACd,MAAM,CAACpC,KAAK,EAAE,GAAGwC,OAAO,CAAC,GAAGH,EAAE,CAACD,IAAI,CAAC;MACpC,IAAI,CAACI,OAAO,CAAChB,MAAM,EAAE,OAAO,CAACxB,KAAK,CAAC;MACnC,OAAO,CAAC,EAAE,CAAC;IACb,CAAC;EACH;EAEA,MAAMgD,WAAW,GAAGf,MAAM,IAAIlC,UAAU;EAExC,IAAI+B,KAAK,CAACL,IAAI,KAAK,UAAU,IAAIQ,MAAM,KAAK,KAAK,EAAE;IACjD,OAAQG,IAAI,IAAI;MACd,MAAMpC,KAAK,GAAGoC,IAAI,CAACN,KAAK,CAACT,IAAI,CAAC;MAC9B,IAAIrB,KAAK,IAAI,IAAI,EAAE,OAAO,CAAC,EAAE,EAAE8B,KAAK,CAACT,IAAI,CAAC;MAE1C,IAAI,CAAC4B,KAAK,CAACC,OAAO,CAAClD,KAAK,CAAC,IAAIA,KAAK,CAACwB,MAAM,KAAK,CAAC,EAAE;QAC/C,MAAM,IAAIX,SAAS,CAAC,aAAaiB,KAAK,CAACT,IAAI,2BAA2B,CAAC;MACzE;MAEA,OAAO,CACLrB,KAAK,CACF2C,GAAG,CAAC,CAAC3C,KAAK,EAAEmB,KAAK,KAAI;QACpB,IAAI,OAAOnB,KAAK,KAAK,QAAQ,EAAE;UAC7B,MAAM,IAAIa,SAAS,CACjB,aAAaiB,KAAK,CAACT,IAAI,IAAIF,KAAK,kBAAkB,CACnD;QACH;QAEA,OAAO6B,WAAW,CAAChD,KAAK,CAAC;MAC3B,CAAC,CAAC,CACDyC,IAAI,CAACN,SAAS,CAAC,CACnB;IACH,CAAC;EACH;EAEA,OAAQC,IAAI,IAAI;IACd,MAAMpC,KAAK,GAAGoC,IAAI,CAACN,KAAK,CAACT,IAAI,CAAC;IAC9B,IAAIrB,KAAK,IAAI,IAAI,EAAE,OAAO,CAAC,EAAE,EAAE8B,KAAK,CAACT,IAAI,CAAC;IAE1C,IAAI,OAAOrB,KAAK,KAAK,QAAQ,EAAE;MAC7B,MAAM,IAAIa,SAAS,CAAC,aAAaiB,KAAK,CAACT,IAAI,kBAAkB,CAAC;IAChE;IAEA,OAAO,CAAC2B,WAAW,CAAChD,KAAK,CAAC,CAAC;EAC7B,CAAC;AACH;AAyBA;;;AAGA,SAAgBL,KAAKA,CACnBoC,IAAmB,EACnBf,OAAA,GAAuC,EAAE;EAEzC,MAAM;IAAEmC,MAAM,GAAGC,kBAAkB;IAAEjB,SAAS,GAAGrC;EAAiB,CAAE,GAClEkB,OAAO;EACT,MAAM;IAAEqC,MAAM;IAAEC;EAAI,CAAE,GAAG1D,YAAY,CAACmC,IAAI,EAAEf,OAAO,CAAC;EAEpD,MAAMuC,QAAQ,GAAGD,IAAI,CAACX,GAAG,CAAEa,GAAG,IAAI;IAChC,IAAIL,MAAM,KAAK,KAAK,EAAE,OAAOpD,UAAU;IACvC,IAAIyD,GAAG,CAAC/B,IAAI,KAAK,OAAO,EAAE,OAAO0B,MAAM;IACvC,OAAQnD,KAAa,IAAKA,KAAK,CAACyD,KAAK,CAACtB,SAAS,CAAC,CAACQ,GAAG,CAACQ,MAAM,CAAC;EAC9D,CAAC,CAAC;EAEF,OAAO,SAASxD,KAAKA,CAAC+D,KAAa;IACjC,MAAMC,CAAC,GAAGN,MAAM,CAACO,IAAI,CAACF,KAAK,CAAC;IAC5B,IAAI,CAACC,CAAC,EAAE,OAAO,KAAK;IAEpB,MAAM5B,IAAI,GAAG4B,CAAC,CAAC,CAAC,CAAC;IACjB,MAAMpB,MAAM,GAAGsB,MAAM,CAACC,MAAM,CAAC,IAAI,CAAC;IAElC,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGJ,CAAC,CAACnC,MAAM,EAAEuC,CAAC,EAAE,EAAE;MACjC,IAAIJ,CAAC,CAACI,CAAC,CAAC,KAAKC,SAAS,EAAE;MAExB,MAAMR,GAAG,GAAGF,IAAI,CAACS,CAAC,GAAG,CAAC,CAAC;MACvB,MAAME,OAAO,GAAGV,QAAQ,CAACQ,CAAC,GAAG,CAAC,CAAC;MAC/BxB,MAAM,CAACiB,GAAG,CAACnC,IAAI,CAAC,GAAG4C,OAAO,CAACN,CAAC,CAACI,CAAC,CAAC,CAAC;IAClC;IAEA,OAAO;MAAEhC,IAAI;MAAEQ;IAAM,CAAE;EACzB,CAAC;AACH;AAEA,SAAgB3C,YAAYA,CAC1BmC,IAAmB,EACnBf,OAAA,GAA8C,EAAE;EAEhD,MAAM;IACJmB,SAAS,GAAGrC,iBAAiB;IAC7BoE,GAAG,GAAG,IAAI;IACVC,SAAS,GAAG,KAAK;IACjBC,QAAQ,GAAG;EAAI,CAChB,GAAGpD,OAAO;EACX,MAAMsC,IAAI,GAAS,EAAE;EACrB,MAAMe,KAAK,GAAGF,SAAS,GAAG,EAAE,GAAG,GAAG;EAClC,MAAMG,OAAO,GAAa,EAAE;EAE5B,KAAK,MAAMZ,KAAK,IAAIa,YAAY,CAACxC,IAAI,EAAE,EAAE,CAAC,EAAE;IAC1C,MAAMK,IAAI,GAAG,OAAOsB,KAAK,KAAK,QAAQ,GAAGA,KAAK,GAAGjE,KAAK,CAACiE,KAAK,EAAE1C,OAAO,CAAC;IACtE,KAAK,MAAMN,MAAM,IAAI8D,OAAO,CAACpC,IAAI,CAAC1B,MAAM,EAAE,CAAC,EAAE,EAAE,CAAC,EAAE;MAChD4D,OAAO,CAAC5C,IAAI,CAAC+C,cAAc,CAAC/D,MAAM,EAAEyB,SAAS,EAAEmB,IAAI,EAAElB,IAAI,CAACzB,YAAY,CAAC,CAAC;IAC1E;EACF;EAEA,IAAI+D,OAAO,GAAG,OAAOJ,OAAO,CAAC7B,IAAI,CAAC,GAAG,CAAC,GAAG;EACzC,IAAI2B,QAAQ,EAAEM,OAAO,IAAI,MAAMnE,MAAM,CAAC4B,SAAS,CAAC,KAAK;EACrDuC,OAAO,IAAIR,GAAG,GAAG,GAAG,GAAG,MAAM3D,MAAM,CAAC4B,SAAS,CAAC,KAAK;EAEnD,MAAMkB,MAAM,GAAG,IAAIsB,MAAM,CAACD,OAAO,EAAEL,KAAK,CAAC;EACzC,OAAO;IAAEhB,MAAM;IAAEC;EAAI,CAAE;AACzB;AAEA;;;AAGA,SAASiB,YAAYA,CAACK,KAAoB,EAAEC,IAAY;EACtD,IAAI5B,KAAK,CAACC,OAAO,CAAC0B,KAAK,CAAC,EAAE;IACxB,KAAK,MAAME,CAAC,IAAIF,KAAK,EAAEL,YAAY,CAACO,CAAC,EAAED,IAAI,CAAC;EAC9C,CAAC,MAAM;IACLA,IAAI,CAACnD,IAAI,CAACkD,KAAK,CAAC;EAClB;EACA,OAAOC,IAAI;AACb;AAOA;;;AAGA,UAAUL,OAAOA,CACf9D,MAAe,EACfS,KAAa,EACb0D,IAAiB;EAEjB,IAAI1D,KAAK,KAAKT,MAAM,CAACc,MAAM,EAAE;IAC3B,OAAO,MAAMqD,IAAI;EACnB;EAEA,MAAM/C,KAAK,GAAGpB,MAAM,CAACS,KAAK,CAAC;EAE3B,IAAIW,KAAK,CAACL,IAAI,KAAK,OAAO,EAAE;IAC1B,KAAK,MAAMsD,GAAG,IAAIP,OAAO,CAAC1C,KAAK,CAACpB,MAAM,EAAE,CAAC,EAAEmE,IAAI,CAACG,KAAK,EAAE,CAAC,EAAE;MACxD,OAAOR,OAAO,CAAC9D,MAAM,EAAES,KAAK,GAAG,CAAC,EAAE4D,GAAG,CAAC;IACxC;EACF,CAAC,MAAM;IACLF,IAAI,CAACnD,IAAI,CAACI,KAAK,CAAC;EAClB;EAEA,OAAO0C,OAAO,CAAC9D,MAAM,EAAES,KAAK,GAAG,CAAC,EAAE0D,IAAI,CAAC;AACzC;AAEA;;;AAGA,SAASJ,cAAcA,CACrB/D,MAAmB,EACnByB,SAAiB,EACjBmB,IAAU,EACV3C,YAAgC;EAEhC,IAAIkC,MAAM,GAAG,EAAE;EACf,IAAIoC,SAAS,GAAG,EAAE;EAClB,IAAIC,kBAAkB,GAAG,IAAI;EAE7B,KAAK,MAAMpD,KAAK,IAAIpB,MAAM,EAAE;IAC1B,IAAIoB,KAAK,CAACL,IAAI,KAAK,MAAM,EAAE;MACzBoB,MAAM,IAAItC,MAAM,CAACuB,KAAK,CAAC9B,KAAK,CAAC;MAC7BiF,SAAS,IAAInD,KAAK,CAAC9B,KAAK;MACxBkF,kBAAkB,KAAlBA,kBAAkB,GAAKpD,KAAK,CAAC9B,KAAK,CAACmF,QAAQ,CAAChD,SAAS,CAAC;MACtD;IACF;IAEA,IAAIL,KAAK,CAACL,IAAI,KAAK,OAAO,IAAIK,KAAK,CAACL,IAAI,KAAK,UAAU,EAAE;MACvD,IAAI,CAACyD,kBAAkB,IAAI,CAACD,SAAS,EAAE;QACrC,MAAM,IAAIrE,SAAS,CACjB,wBAAwBkB,KAAK,CAACT,IAAI,KAAKS,KAAK,CAACL,IAAI,EAAE,EACnDd,YAAY,CACb;MACH;MAEA,IAAImB,KAAK,CAACL,IAAI,KAAK,OAAO,EAAE;QAC1BoB,MAAM,IAAI,IAAIuC,MAAM,CAACjD,SAAS,EAAE+C,kBAAkB,GAAG,EAAE,GAAGD,SAAS,CAAC,IAAI;MAC1E,CAAC,MAAM;QACLpC,MAAM,IAAI,aAAa;MACzB;MAEAS,IAAI,CAAC5B,IAAI,CAACI,KAAK,CAAC;MAChBmD,SAAS,GAAG,EAAE;MACdC,kBAAkB,GAAG,KAAK;MAC1B;IACF;EACF;EAEA,OAAOrC,MAAM;AACf;AAEA;;;AAGA,SAASuC,MAAMA,CAACjD,SAAiB,EAAE8C,SAAiB;EAClD,IAAIA,SAAS,CAACzD,MAAM,GAAG,CAAC,EAAE;IACxB,IAAIW,SAAS,CAACX,MAAM,GAAG,CAAC,EAAE,OAAO,KAAKjB,MAAM,CAAC4B,SAAS,GAAG8C,SAAS,CAAC,GAAG;IACtE,OAAO,SAAS1E,MAAM,CAAC4B,SAAS,CAAC,MAAM5B,MAAM,CAAC0E,SAAS,CAAC,IAAI;EAC9D;EACA,IAAI9C,SAAS,CAACX,MAAM,GAAG,CAAC,EAAE;IACxB,OAAO,SAASjB,MAAM,CAAC0E,SAAS,CAAC,MAAM1E,MAAM,CAAC4B,SAAS,CAAC,IAAI;EAC9D;EACA,OAAO,SAAS5B,MAAM,CAAC0E,SAAS,CAAC,IAAI1E,MAAM,CAAC4B,SAAS,CAAC,YAAY;AACpE;AAEA;;;AAGA,SAASkD,eAAeA,CAAC3E,MAAe;EACtC,IAAIV,KAAK,GAAG,EAAE;EACd,IAAI+D,CAAC,GAAG,CAAC;EAET,SAAS1C,IAAIA,CAACrB,KAAa;IACzB,MAAMsF,MAAM,GAAGC,UAAU,CAACvF,KAAK,CAAC,IAAIwF,cAAc,CAAC9E,MAAM,CAACqD,CAAC,CAAC,CAAC;IAC7D,OAAOuB,MAAM,GAAGtF,KAAK,GAAGyF,IAAI,CAAC5F,SAAS,CAACG,KAAK,CAAC;EAC/C;EAEA,OAAO+D,CAAC,GAAGrD,MAAM,CAACc,MAAM,EAAE;IACxB,MAAMM,KAAK,GAAGpB,MAAM,CAACqD,CAAC,EAAE,CAAC;IAEzB,IAAIjC,KAAK,CAACL,IAAI,KAAK,MAAM,EAAE;MACzBzB,KAAK,IAAII,UAAU,CAAC0B,KAAK,CAAC9B,KAAK,CAAC;MAChC;IACF;IAEA,IAAI8B,KAAK,CAACL,IAAI,KAAK,OAAO,EAAE;MAC1BzB,KAAK,IAAI,IAAIqF,eAAe,CAACvD,KAAK,CAACpB,MAAM,CAAC,GAAG;MAC7C;IACF;IAEA,IAAIoB,KAAK,CAACL,IAAI,KAAK,OAAO,EAAE;MAC1BzB,KAAK,IAAI,IAAIqB,IAAI,CAACS,KAAK,CAACT,IAAI,CAAC,EAAE;MAC/B;IACF;IAEA,IAAIS,KAAK,CAACL,IAAI,KAAK,UAAU,EAAE;MAC7BzB,KAAK,IAAI,IAAIqB,IAAI,CAACS,KAAK,CAACT,IAAI,CAAC,EAAE;MAC/B;IACF;IAEA,MAAM,IAAIR,SAAS,CAAC,uBAAwBiB,KAAa,CAACL,IAAI,EAAE,CAAC;EACnE;EAEA,OAAOzB,KAAK;AACd;AAEA;;;AAGA,SAAgBH,SAASA,CAACuC,IAAe;EACvC,OAAOiD,eAAe,CAACjD,IAAI,CAAC1B,MAAM,CAAC;AACrC;AAEA;;;AAGA,SAAS6E,UAAUA,CAAClE,IAAY;EAC9B,MAAM,CAACqE,KAAK,EAAE,GAAGC,IAAI,CAAC,GAAGtE,IAAI;EAC7B,OAAOpB,QAAQ,CAACqB,IAAI,CAACoE,KAAK,CAAC,IAAIC,IAAI,CAACC,KAAK,CAAEC,IAAI,IAAK3F,WAAW,CAACoB,IAAI,CAACuE,IAAI,CAAC,CAAC;AAC7E;AAEA;;;AAGA,SAASL,cAAcA,CAAC1D,KAAwB;EAC9C,IAAIA,KAAK,IAAIA,KAAK,CAACL,IAAI,KAAK,MAAM,EAAE,OAAO,CAACvB,WAAW,CAACoB,IAAI,CAACQ,KAAK,CAAC9B,KAAK,CAAC,CAAC,CAAC,CAAC;EAC5E,OAAO,IAAI;AACb","ignoreList":[]},"metadata":{},"sourceType":"script","externalDependencies":[]}